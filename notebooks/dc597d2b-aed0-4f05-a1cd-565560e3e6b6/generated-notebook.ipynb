{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "592ebe9a",
   "metadata": {},
   "source": [
    "Before running, install required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd071bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install numpy sklearn torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135ced1a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f9a6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.linear_model import Perceptron\n",
    "from torchvision import datasets, transforms\n",
    "import urllib\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e642693",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# COMMENT THIS OUT IF YOU USE YOUR OWN DATA.\n",
    "# Download example data into ./data/image-data (4 image files, 2 for \"dog\", 2 for \"cat\").\n",
    "url = \"https://github.com/jrieke/traingenerator/raw/main/data/fake-image-data.zip\"\n",
    "zip_path, _ = urllib.request.urlretrieve(url)\n",
    "with zipfile.ZipFile(zip_path, \"r\") as f:\n",
    "    f.extractall(\"data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d1e1ce",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c76e4d",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# INSERT YOUR DATA HERE\n",
    "# Expected format: One folder per class, e.g.\n",
    "# train\n",
    "# --- dogs\n",
    "# |   +-- lassie.jpg\n",
    "# |   +-- komissar-rex.png\n",
    "# --- cats\n",
    "# |   +-- garfield.png\n",
    "# |   +-- smelly-cat.png\n",
    "#\n",
    "# Example: https://github.com/jrieke/traingenerator/tree/main/data/image-data\n",
    "train_data = \"data/image-data\"  # required\n",
    "val_data = \"data/image-data\"    # optional\n",
    "test_data = None                # optional"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b063cc2",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0b765b",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Set up scaler.\n",
    "scaler = sklearn.preprocessing.StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d8d340",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def preprocess(data, name):\n",
    "    if data is None:  # val/test can be empty\n",
    "        return None\n",
    "    # Read image files to pytorch dataset (only temporary).\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(26), \n",
    "        transforms.CenterCrop(26), \n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    data = datasets.ImageFolder(data, transform=transform)\n",
    "\n",
    "    # Convert to numpy arrays.\n",
    "    images_shape = (len(data), *data[0][0].shape)\n",
    "    images = np.zeros(images_shape)\n",
    "    labels = np.zeros(len(data))\n",
    "    for i, (image, label) in enumerate(data):\n",
    "        images[i] = image\n",
    "        labels[i] = label\n",
    "    \n",
    "    # Flatten.\n",
    "    images = images.reshape(len(images), -1)\n",
    "\n",
    "    # Scale to mean 0 and std 1.\n",
    "    if name == \"train\":\n",
    "        scaler.fit(images)\n",
    "    images = scaler.transform(images)\n",
    "\n",
    "    # Shuffle train set.\n",
    "    if name == \"train\":\n",
    "        images, labels = sklearn.utils.shuffle(images, labels)\n",
    "\n",
    "    return [images, labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b258c1",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "processed_train_data = preprocess(train_data, \"train\")\n",
    "processed_val_data = preprocess(val_data, \"val\")\n",
    "processed_test_data = preprocess(test_data, \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c24d44c",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7d988e",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "model = Perceptron()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f87af0",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488ad190",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def evaluate(data, name):\n",
    "    if data is None:  # val/test can be empty\n",
    "        return\n",
    "\n",
    "    images, labels = data\n",
    "    acc = model.score(images, labels)\n",
    "    print(f\"{name + ':':6} accuracy: {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea81bd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train on train_data.\n",
    "model.fit(*processed_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6bc770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on all datasets.\n",
    "evaluate(processed_train_data, \"train\")\n",
    "evaluate(processed_val_data, \"val\")\n",
    "evaluate(processed_test_data, \"test\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}