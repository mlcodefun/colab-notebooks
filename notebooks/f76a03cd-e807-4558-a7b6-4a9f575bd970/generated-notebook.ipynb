{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41e85d8c",
   "metadata": {},
   "source": [
    "Before running, install required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebec0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install numpy sklearn torchvision tensorboardX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27b64e3",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a421463",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from torchvision import datasets, transforms\n",
    "import urllib\n",
    "import zipfile\n",
    "from tensorboardX import SummaryWriter\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94aa661",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# COMMENT THIS OUT IF YOU USE YOUR OWN DATA.\n",
    "# Download example data into ./data/image-data (4 image files, 2 for \"dog\", 2 for \"cat\").\n",
    "url = \"https://github.com/jrieke/traingenerator/raw/main/data/fake-image-data.zip\"\n",
    "zip_path, _ = urllib.request.urlretrieve(url)\n",
    "with zipfile.ZipFile(zip_path, \"r\") as f:\n",
    "    f.extractall(\"data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8757fc5c",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6e0a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSERT YOUR DATA HERE\n",
    "# Expected format: One folder per class, e.g.\n",
    "# train\n",
    "# --- dogs\n",
    "# |   +-- lassie.jpg\n",
    "# |   +-- komissar-rex.png\n",
    "# --- cats\n",
    "# |   +-- garfield.png\n",
    "# |   +-- smelly-cat.png\n",
    "#\n",
    "# Example: https://github.com/jrieke/traingenerator/tree/main/data/image-data\n",
    "train_data = \"data/image-data\"  # required\n",
    "val_data = \"data/image-data\"    # optional\n",
    "test_data = None                # optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3796472b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Set up logging.\n",
    "experiment_id = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "writer = SummaryWriter(logdir=f\"logs/{experiment_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676f9749",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748a9dd3",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Set up scaler.\n",
    "scaler = sklearn.preprocessing.StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230d47ab",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def preprocess(data, name):\n",
    "    if data is None:  # val/test can be empty\n",
    "        return None\n",
    "    # Read image files to pytorch dataset (only temporary).\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(28), \n",
    "        transforms.CenterCrop(28), \n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    data = datasets.ImageFolder(data, transform=transform)\n",
    "\n",
    "    # Convert to numpy arrays.\n",
    "    images_shape = (len(data), *data[0][0].shape)\n",
    "    images = np.zeros(images_shape)\n",
    "    labels = np.zeros(len(data))\n",
    "    for i, (image, label) in enumerate(data):\n",
    "        images[i] = image\n",
    "        labels[i] = label\n",
    "    \n",
    "    # Flatten.\n",
    "    images = images.reshape(len(images), -1)\n",
    "\n",
    "    # Scale to mean 0 and std 1.\n",
    "    if name == \"train\":\n",
    "        scaler.fit(images)\n",
    "    images = scaler.transform(images)\n",
    "\n",
    "    # Shuffle train set.\n",
    "    if name == \"train\":\n",
    "        images, labels = sklearn.utils.shuffle(images, labels)\n",
    "\n",
    "    return [images, labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a772f9c9",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "processed_train_data = preprocess(train_data, \"train\")\n",
    "processed_val_data = preprocess(val_data, \"val\")\n",
    "processed_test_data = preprocess(test_data, \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da1f90d",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6215f8dd",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "model = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0c4c44",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be59e4b",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def evaluate(data, name):\n",
    "    if data is None:  # val/test can be empty\n",
    "        return\n",
    "\n",
    "    images, labels = data\n",
    "    acc = model.score(images, labels)\n",
    "    print(f\"{name + ':':6} accuracy: {acc}\")\n",
    "    writer.add_scalar(f\"{name}_accuracy\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad31a34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train on train_data.\n",
    "model.fit(*processed_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30866f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on all datasets.\n",
    "evaluate(processed_train_data, \"train\")\n",
    "evaluate(processed_val_data, \"val\")\n",
    "evaluate(processed_test_data, \"test\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}